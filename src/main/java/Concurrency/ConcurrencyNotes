Concurrency

Thread class
    A Thread constructor only needs a Runnable object. Calling a Thread object’s start( )
    will perform the necessary initialization for the thread and then call that Runnable’s run( )
    method to start the task in the new thread.

Executor class
    In Java SE5 java.util.concurrent Executors simplify concurrent programming by managing
    Thread objects for you. Executors provide a layer of indirection between a client and the
    execution of a task; instead of a client executing a task directly, an intermediate object
    executes the task. Executors allow you to manage the execution of asynchronous tasks
    without having to explicitly manage the lifecycle of threads. Executors are the preferred
    method for starting tasks in Java SE5/6.

        With the FixedThreadPool, you do expensive thread allocation once, up front, and you
        thus limit the number of threads.

        A CachedThreadPool will generally create as many threads as it needs
        during the execution of a program and then will stop creating new threads as it recycles the
        old ones, so it’s a reasonable first choice as an Executor.

        A SingleThreadExecutor is like a FixedThreadPool with a size of one thread. 7 This is
        useful for anything you want to run in another thread continually (a long-lived task), such as
        a task that listens to incoming socket connections. It is also handy for short tasks that you
        want to run in a thread— for example, small tasks that update a local or remote log, or for an
        eventdispatching thread.

Callable class
    If you want the task to produce a value when it’s done, you can implement the Callable interface rather
    than the Runnable interface. Callable, introduced in Java SE5, is a generic with a type
    parameter representing the return value from the method call( ) (instead of run( )), and
    must be invoked using an ExecutorService submit( ) method.

Sleeping
    A simple way to affect the behavior of your tasks is by calling sleep( ) to cease (block) the
    execution of that task for a given time. In the LiftOff class, if you replace the call to yield( )
    with a call to sleep().

    Java SE5 introduced the more explicit version of sleep( ) as part of the TimeUnit class, as
    shown in the above example. This provides better readability by allowing you to specify the
    units of the sleep( ) delay. TimeUnit can also be used to perform conversions, as you shall
    see later in the chapter.

Priority
    The priority of a thread conveys the importance of a thread to the scheduler. Although the
    order in which the CPU runs a set of threads is indeterminate, the scheduler will lean toward
    running the waiting thread with the highest priority first. However, this doesn’t mean that
    threads with lower priority aren’t run (so you can’t get deadlocked because of priorities).
    Lower-priority threads just tend to run less often.

    You can read the priority of an existing
    thread with getPriority( ) and change it at any time with setPriority( ).

Yielding
    If you know that you’ve accomplished what you need to during one pass through a loop in
    your run( ) method, you can give a hint to the threadscheduling mechanism that you’ve
    done enough and that some other task might as well have the CPU. This hint (and it is a
    hint—there’s no guarantee your implementation will listen to it) takes the form of the
    yield( ) method. When you call yield( ), you are suggesting that other threads of the same
    priority might be run.

Daemon threads
    A "daemon" thread is intended to provide a general service in the background as long as the
    program is running, but is not part of the essence of the program. Thus, when all of the non-
    daemon threads complete, the program is terminated, killing all daemon threads in the
    process. Conversely, if there are any non-daemon threads still running, the program doesn’t
    terminate. There is, for instance, a non-daemon thread that runs main( ).

Joining threads
    One thread may call join( ) on another thread to wait for the second thread to complete
    before proceeding. If a thread calls t.join( ) on another thread t, then the calling thread is
    suspended until the target thread t finishes (when t.isAlive( ) is false).

    You may also call join( ) with a timeout argument (in either milliseconds or milliseconds
    and nanoseconds) so that if the target thread doesn’t finish in that period of time, the call to
    join( ) returns anyway.

    The call to join( ) may be aborted by calling interrupt( ) on the calling thread, so a try-
    catch clause is required.

Sharing resources
Syncronized
    To prevent collisions over resources, Java has built-in support in the form of the
    synchronized keyword. When a task wishes to execute a piece of code guarded by the
    synchronized keyword, it checks to see if the lock is available, then acquires it, executes the
    code, and releases it.

    "If you are writing a variable that might next be read by another thread, or reading a
    variable that might have last been written by another thread, you must use
    synchronization, and further, both the reader and the writer must synchronize using the
    same monitor lock."


Lock
    The Java SE5 java.util.concurrent library also contains an explicit mutex mechanism
    defined in java.util.concurrent.locks. The Lock object must be explicitly created, locked
    and unlocked; thus, it produces less elegant code than the built-in form. However, it is more
    flexible for solving certain types of problems.

    In general, when you are using synchronized, there is less code to write, and the
    opportunity for user error is greatly reduced, so you’ll usually only use the explicit Lock
    objects when you’re solving special problems. For example, with the synchronized
    keyword, you can’t try and fail to acquire a lock, or try to acquire a lock for a certain amount
    of time and then give up—to do this, you must use the concurrent library.

Atomicity
    Atomicity applies to "simple operations" on primitive types except for longs and doubles.
    Reading and writing primitive variables other than long and double is guaranteed to go to
    and from memory as indivisible (atomic) operations. However, the JVM is allowed to
    perform reads and writes of 64- bit quantities (long and double variables) as two separate
    32-bit operations, raising the possibility that a context switch could happen in the middle of a
    read or write, and then different tasks could see incorrect results (this is sometimes called
    word tearing, because you might see the value after only part of it has been changed).
    However, you do get atomicity (for simple assignments and returns) if you use the volatile
    keyword when defining a long or double variable (note that volatile was not working
    properly before Java SE5). Different JVMs are free to provide stronger guarantees, but you
    should not rely on platform-specific features.

Volatility
    The volatile keyword also ensures visibility across the application. If you declare a field to be
    volatile, this means that as soon as a write occurs for that field, all reads will see the change.
    This is true even if local caches are involved—volatile fields are immediately written through
    to main memory, and reads occur from main memory.

    It’s important to understand that atomicity and volatility are distinct concepts. An atomic
    operation on a non-volatile field will not necessarily be flushed to main memory, and so
    another task that reads that field will not necessarily see the new value. If multiple tasks are
    accessing a field, that field should be volatile; otherwise, the field should only be accessed
    via synchronization. Synchronization also causes flushing to main memory, so if a field is
    completely guarded by synchronized methods or blocks, it is not necessary to make it
    volatile.

Atomic classes
    Java SE5 introduces special atomic variable classes such as Atomiclnteger, AtomicLong,
    AtomicReference, etc. that provide an atomic conditional update operation of the form:
    boolean compareAndSet(expectedValue, updateValue);

    These are for fine-tuning to use machine-level atomicity that is available on some modern
    processors, so you generally don’t need to worry about using them. Occasionally they come in
    handy for regular coding, but again when performance tuning is involved.

